{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xtuples\n",
    "\n",
    "[![PyPI - Version](https://img.shields.io/pypi/v/xtuples.svg)](https://pypi.org/project/xtuples)\n",
    "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/xtuples.svg)](https://pypi.org/project/xtuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "\n",
    "- [Installation](#installation)\n",
    "- [Overview](#overview)\n",
    "- [Examples](#examples)\n",
    "- [Performance](#performance)\n",
    "- [JSON](#xtuples.json)\n",
    "- [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```console\n",
    "pip install xtuples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtuples is designed to make functional programming easier in Python.\n",
    "\n",
    "In particular, it is designed to enable one to mimic the function pipelines seen in languages like f#, but using method chaining.\n",
    "\n",
    "The two key constructs are:\n",
    "\n",
    "- xtuples.iTuple: a tuple class class equipped with methods like .map() .filter() and .fold().\n",
    "\n",
    "- xuples.nTuple.decorate: a decorator to inject .pipe() .partial() and a dict of user defined methods into NamedTuples (as we can't subclass them directly).\n",
    "\n",
    "Taken together, these tend to lead us away from inheritance, and more towards composition: to a code base comprised entirely of either free functions, or (immutable) data structures implemented using either of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance\n",
    "\n",
    "Performance using xtuples should generally be, at worst, not (materially) worse than a non-optimised canonical equivalent (and can sometimes be somewhat better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iTuple\n",
    "\n",
    "For instance, iTuple is simply a subclass of the built-in tuple, so has very similar performance characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, creation is slightly slower than for an equivalent length list (at least when initialised from range):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56 µs ± 9.4 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "588 ns ± 11.3 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit xtuples.iTuple.range(10 ** 2)\n",
    "%timeit list(range(10 ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 µs ± 128 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "7.97 µs ± 60.2 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit xtuples.iTuple.range(10 ** 3)\n",
    "%timeit list(range(10 ** 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 µs ± 1.51 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "89.6 µs ± 817 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit xtuples.iTuple.range(10 ** 4)\n",
    "%timeit list(range(10 ** 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.9 ms ± 1.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "24.5 ms ± 424 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit xtuples.iTuple.range(10 ** 6)\n",
    "%timeit list(range(10 ** 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas memory usage (comparable for small sizes), gets increasingly more efficient with size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'iTuple': 160, 'list': 88},\n",
       " 1: {'iTuple': 232, 'list': 448},\n",
       " 2: {'iTuple': 952, 'list': 4048},\n",
       " 3: {'iTuple': 8152, 'list': 40048},\n",
       " 4: {'iTuple': 80152, 'list': 400048}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = {}\n",
    "for i in range(5):\n",
    "    memory[i] = dict(\n",
    "        iTuple=asizeof(xtuples.iTuple.range(10 ** i)),\n",
    "        list=asizeof(list(range(10 ** i))),\n",
    "    )\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_iTuple = xtuples.iTuple.range(100)\n",
    "ex_list = list(range(100))\n",
    "ex_range = range(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration & Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration is very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 ns ± 4.57 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "721 ns ± 24.1 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for x in ex_iTuple: pass\n",
    "%timeit for x in ex_list: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And whilst elementwise indexing is clearly slower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.6 µs ± 240 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "2.84 µs ± 75.3 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit for i in range(100): ex_iTuple[i]\n",
    "%timeit for i in range(100): ex_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so is slice indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667 ns ± 10.3 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "93.9 ns ± 0.998 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ex_iTuple[10:20]\n",
    "%timeit ex_list[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that per element indexing is not all that common using xtuples (as the canonical implementation is much more likely to use .map() and co)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending is *much* slower, which is clearly to some extent a 'gotcha'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56 µs ± 22.9 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "69.3 ns ± 6.18 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ex_iTuple.append(1)\n",
    "%timeit ex_list.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having said that, the canonical xtuples implementation is much more likely to use .map() .foldcum() or similar than .append().\n",
    "\n",
    "And, as you can see below, .map() and .foldcum() are actually *faster* than the for-loop & append() implementations.\n",
    "\n",
    "So, as with elementwise indexing, in the context of a canonical implementation of an entire function, performance is generally on par (if not better) with xtuples as with the equivalent built-ins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepend / Extend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepending to the tuple is *much* faster than with the list, though the relevant comparison is probably a deque (given that list is not at all optimised for left-append):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 µs ± 11 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "109 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ex_iTuple.prepend(1)\n",
    "%timeit ex_list.insert(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend is somewhat slower (but is nowhere near as bad as append):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.93 µs ± 32.3 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "5.58 µs ± 43.4 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "769 ns ± 8.37 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "1.48 µs ± 19 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit xtuples.iTuple.range(100).extend([1])\n",
    "%timeit xtuples.iTuple.range(100).extend(list(range(100)))\n",
    "%timeit list(range(100)).extend([1])\n",
    "%timeit list(range(100)).extend(list(range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And flatten is *much* faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.38 µs ± 81.1 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "ex_iTuple_nested = ex_iTuple.map(lambda v: [v])\n",
    "ex_list_nested = [[v] for v in ex_list]\n",
    "\n",
    "def f_loop_flatten(l):\n",
    "    for v in l:\n",
    "        yield from v\n",
    "\n",
    "%timeit ex_iTuple_nested.flatten()\n",
    "%timeit list(f_loop_flatten(ex_list_nested))\n",
    "%timeit list(itertools.chain(*ex_list_nested))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, elementwise function application with .map() is *much* faster than the equivalent loop or list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_2 = functools.partial(operator.add, 2)\n",
    "\n",
    "def f_loop_map(f, l):\n",
    "    res = []\n",
    "    for v in l:\n",
    "        res.append(f(v))\n",
    "    return res\n",
    "\n",
    "%timeit ex_iTuple.map(add_2)\n",
    "%timeit f_loop_map(add_2, ex_list)\n",
    "%timeit [add_2(x) for x in ex_list]\n",
    "%timeit list(map(add_2, ex_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is elementwise filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loop_filter(f):\n",
    "    res = []\n",
    "    for i in ex_list:\n",
    "        if f(i):\n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "f = lambda x: x % 2 == 0\n",
    "\n",
    "%timeit ex_iTuple.filter(f)\n",
    "%timeit f_loop_filter(f)\n",
    "%timeit [v for v in ex_list if f(v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, so are both fold and cumulative fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loop_fold():\n",
    "    acc = 0\n",
    "    for i in ex_list:\n",
    "        acc = operator.add(acc, i)\n",
    "    return acc\n",
    "\n",
    "%timeit ex_iTuple.fold(operator.add)\n",
    "%timeit f_loop_fold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, as mentioned above, the answer to the poor .append() performance is often just to use .foldcum() instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loop_foldcum():\n",
    "    res = []\n",
    "    acc = 0\n",
    "    for i in ex_list:\n",
    "        acc = operator.add(acc, i)\n",
    "        res.append(acc)\n",
    "    return res\n",
    "\n",
    "%timeit ex_iTuple.foldcum(operator.add)\n",
    "%timeit f_loop_foldcum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, iTuple performance and memory usage is comparable - if not better - than a raw list.\n",
    "\n",
    "The one clear weak point is .append().\n",
    "\n",
    "But, *if used as intended*, the canonical xtuples implementation would instead likely be using .map() .foldcum() and co.\n",
    "\n",
    "Given that .map() .filter() .fold() and .foldcum() are generally *much* faster than the equivalent for loops or list comprehensions, performance is often actually *better* than the equivalent implementation using only built-ins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Tuple\n",
    "\n",
    "nTuple does *not* (in comparison to iTuple) define a base class for us to sub-class.\n",
    "\n",
    "Rather, it provides a decorator - nTuple.decorate - that adds .pipe() .partial() and a dict of user defined methods to a given NamedTuple.\n",
    "\n",
    "As such, performance is essentially just that of built-in NamedTuples (ie. generally very strong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE, re-registering: Example\n"
     ]
    }
   ],
   "source": [
    "@xtuples.nTuple.decorate(\n",
    "    update_x = lambda self, x: self._replace(x=x), \n",
    "    update_s = lambda self, s: self._replace(s=s),\n",
    ")\n",
    "class Example(typing.NamedTuple):\n",
    "    x: int\n",
    "    s: str\n",
    "    \n",
    "class Example_Cls:\n",
    "    x: int\n",
    "    s: str\n",
    "    \n",
    "    def __init__(self, x, s):\n",
    "        self.x = x\n",
    "        self.s = s\n",
    "\n",
    "@dataclasses.dataclass(frozen=True, eq=True)\n",
    "class Example_DC:\n",
    "    x: int\n",
    "    s: str\n",
    "    \n",
    "ex_nTuple = Example(1, \"a\")\n",
    "ex_dict = dict(x=1, s=\"a\")\n",
    "ex_cls = Example_Cls(1, \"a\")\n",
    "ex_dc = Example_DC(1, \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, NamedTuples are significantly more memory efficient than any of the possible alternatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nTuple': 144, 'dict': 432, 'cls': 352, 'dataclass': 352}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(\n",
    "    nTuple=asizeof(ex_nTuple),\n",
    "    dict=asizeof(ex_dict),\n",
    "    cls=asizeof(ex_cls),\n",
    "    dataclass=asizeof(ex_dc),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 ns ± 8.92 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "111 ns ± 1.53 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "209 ns ± 2.58 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "443 ns ± 3.05 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Example(1, \"a\")\n",
    "%timeit dict(x=1, s=\"a\")\n",
    "%timeit Example_Cls(1, \"a\")\n",
    "%timeit Example_DC(1, \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst providing comparable (if not slightly faster) field access times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.7 ns ± 0.303 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "25.1 ns ± 0.0815 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "29.7 ns ± 0.181 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "30.3 ns ± 0.492 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "34.9 ns ± 0.125 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ex_nTuple.x\n",
    "%timeit ex_nTuple[0]\n",
    "%timeit ex_dict[\"x\"]\n",
    "%timeit ex_cls.x\n",
    "%timeit ex_dc.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes are, however, slower - the price we pay for immutability (and still faster than the frozen dataclass equivalent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.4 ns ± 0.467 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "43.8 ns ± 0.524 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n",
      "735 ns ± 5.93 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "1.03 µs ± 3.35 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "1.28 µs ± 4.37 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ex_dict[\"x\"] = 1\n",
    "%timeit ex_cls.x = 1\n",
    "%timeit ex_nTuple._replace(x = 1)\n",
    "&timeit ex_nTuple.update_x(x)\n",
    "%timeit ex_nTuple.update(x=1)\n",
    "%timeit dataclasses.replace(ex_dc, x=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like frozen dataclasses, NamedTuples are conveniently hashable (in comparison to dicts, for instance, which aren't), and do so based on value (versus standard classes which use object ids by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nTuple': True, 'cls': False, 'dataclass': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(\n",
    "    nTuple= hash(ex_nTuple) == hash(Example(1, \"a\")),\n",
    "    cls= hash(ex_cls) == hash(Example_Cls(1, \"a\")),\n",
    "    dataclass= hash(ex_dc) == hash(Example_DC(1, \"a\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is particularly useful in combination with iTuple, which is also hashable (making combinations of the two recursively hashable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@xtuples.nTuple.decorate\n",
    "class Example_Nested(typing.NamedTuple):\n",
    "    x: int\n",
    "    s: str\n",
    "    \n",
    "    it: xtuples.iTuple\n",
    "    \n",
    "hash(Example_Nested(1, \"s\", xtuples.iTuple())) == hash(Example_Nested(1, \"s\", xtuples.iTuple()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sorting is both provided by default (again, in comparison to dicts and classes), and works as one would expect (ie. by the first field, then the second field, and so on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iTuple(Example(x=1, s='a'), Example(x=1, s='b'), Example(x=2, s='a'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtuples.iTuple([\n",
    "    Example(2, \"a\"),\n",
    "    Example(1, \"b\"),\n",
    "    Example(1, \"a\"),\n",
    "]).sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## xtuples.json\n",
    "\n",
    "xtuples.json provides base classes for weakly-rich json encoding / decoding (rich in that classes are preserved, weak in that this is based on class name alone and no further checks or guarantees are provided)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## License\n",
    "\n",
    "`xtuples` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
